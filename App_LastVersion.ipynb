{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c658685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "import tkinter as tk\n",
    "import PIL.Image\n",
    "from PIL import Image, ImageTk\n",
    "from PIL import ImageDraw # для отрисовки 68 landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7487a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import shutil # для копирование файлов\n",
    "import imgaug # для аугментации\n",
    "from imgaug import augmenters as iaa # для аугментации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec9ee94",
   "metadata": {},
   "source": [
    "# Сериализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cccf2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class Serializer_DB:\n",
    "    \n",
    "    name_of_db = 'db_persons.pkl'\n",
    "    \n",
    "    # сохранение данных в файле\n",
    "    # known_face_encodings - кодировки лиц (128d векторы)\n",
    "    # known_face_names - именя людей в соответсвии к кодировкам\n",
    "    # data_labels - номера людей для классификации\n",
    "    @staticmethod\n",
    "    def save_data_to_file(known_face_encodings, known_face_names, data_labels):\n",
    "    \n",
    "        db_for_serialize = { \"encodings\" : known_face_encodings,\n",
    "                             \"names\" : known_face_names,\n",
    "                             \"labels\" : data_labels}\n",
    "        print(\"Writing DB to file...\")\n",
    "        pickle.dump(db_for_serialize, open(Serializer_DB.name_of_db, 'wb'))\n",
    "\n",
    "    # получение данных из файла\n",
    "    @staticmethod\n",
    "    def read_data_from_file():\n",
    "        print(\"Reading DB from file...\")\n",
    "        db_from_serialize = pickle.load(open(Serializer_DB.name_of_db, 'rb'))\n",
    "        return db_from_serialize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60a42b3",
   "metadata": {},
   "source": [
    "# Нормализация фотографии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f8991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# класс описывающий нормализацию изображения лица\n",
    "class FaceNormalizer:\n",
    "    \n",
    "    FACIAL_LANDMARKS_5_POINTS = OrderedDict([\n",
    "    (\"right_eye\", (2, 3)),\n",
    "    (\"left_eye\", (0, 1)),\n",
    "    (\"nose\", (4))\n",
    "    ])\n",
    "    \n",
    "    def __init__(self, predictor, desiredLeftEye=(0.33, 0.33),\n",
    "        desiredFaceWidth=256, desiredFaceHeight=None):\n",
    "        # сохранение определителя ключевых точек лица, желаемая позиция левого глаза\n",
    "        # и желаемая ширина и высота лица на выходящем изображении\n",
    "        self.predictor_landmarks = predictor\n",
    "        self.desiredLeftEye = desiredLeftEye\n",
    "        self.desiredFaceWidth = desiredFaceWidth\n",
    "        self.desiredFaceHeight = desiredFaceHeight\n",
    "        # if the desired face height is None, set it to be the\n",
    "        # desired face width (normal behavior)\n",
    "        if self.desiredFaceHeight is None:\n",
    "            self.desiredFaceHeight = self.desiredFaceWidth\n",
    "            \n",
    "    # функция для нормализации лица\n",
    "    # image - изображение в RGB \n",
    "    # gray - серое изображение\n",
    "    # rect - область лица, выделенная HOG\n",
    "    def align(self, image, gray, rect):\n",
    "        # получение 5 ориентиров-landmarks\n",
    "        shape = self.predictor_landmarks(image, rect)\n",
    "        # преобразование dlib object в np.array\n",
    "        shape = self.shape_to_np(shape)\n",
    "        \n",
    "        # извлечение левого и правого глаз (x, y)-coordinates\n",
    "        (lStart, lEnd) = self.FACIAL_LANDMARKS_5_POINTS[\"left_eye\"]\n",
    "        (rStart, rEnd) = self.FACIAL_LANDMARKS_5_POINTS[\"right_eye\"]\n",
    "        # извлечение точек левого глаза и правого (x, y)-coordinates\n",
    "        leftEyePts = shape[lStart:lEnd + 1]\n",
    "        rightEyePts = shape[rStart:rEnd + 1]\n",
    "        \n",
    "        # расчет центра для каждого глаза\n",
    "        leftEyeCenter = leftEyePts.mean(axis=0).astype(\"int\")\n",
    "        rightEyeCenter = rightEyePts.mean(axis=0).astype(\"int\")\n",
    "        # расчет угла между центроидами глаз\n",
    "        dY = rightEyeCenter[1] - leftEyeCenter[1]\n",
    "        dX = rightEyeCenter[0] - leftEyeCenter[0]\n",
    "        angle = np.degrees(np.arctan2(dY, dX)) - 180\n",
    "        #print(angle)\n",
    "        \n",
    "        # вычисление х-коорд правого глаза основанной на x-коорд левого глаза\n",
    "        desiredRightEyeX = 1.0 - self.desiredLeftEye[0]\n",
    "        # определение масштаба результирующего изображения, взяв\n",
    "        # отношение расстояния между глазами в текущем изображении\n",
    "        # к отношению расстояния глаз в желаемом изображении\n",
    "        dist = np.sqrt((dX ** 2) + (dY ** 2)) # Евклидово расстояние\n",
    "        desiredDist = (desiredRightEyeX - self.desiredLeftEye[0]) # \n",
    "        desiredDist *= self.desiredFaceWidth\n",
    "        scale = desiredDist / dist\n",
    "        \n",
    "        # вычисление центра между глазами (x, y)-coordinates\n",
    "        # для вращения фотографии вокруг этого центра\n",
    "        eyesCenter = ((leftEyeCenter[0] + rightEyeCenter[0]) / 2,\n",
    "        (leftEyeCenter[1] + rightEyeCenter[1]) / 2)\n",
    "        #print(\"eyesCenter = \" + str(eyesCenter))\n",
    "        \n",
    "        # получение матрицы для поворота и масштабирования лица\n",
    "        M = cv2.getRotationMatrix2D(center=eyesCenter, angle=angle, scale=scale)\n",
    "        \n",
    "        # обновление компонентов матрицы на смещение\n",
    "        tX = self.desiredFaceWidth * 0.5\n",
    "        tY = self.desiredFaceHeight * self.desiredLeftEye[1]\n",
    "        M[0, 2] += (tX - eyesCenter[0])\n",
    "        M[1, 2] += (tY - eyesCenter[1])\n",
    "        \n",
    "        # применение аффинного преобразования\n",
    "        (w, h) = (self.desiredFaceWidth, self.desiredFaceHeight)\n",
    "        output = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # возвращение нормализованного лица\n",
    "        return output\n",
    "\n",
    "    # dlib object -> np.array\n",
    "    def shape_to_np(self, shape, dtype=\"int\"):\n",
    "        # initialize the list of (x, y)-coordinates\n",
    "        coords = np.zeros((shape.num_parts, 2), dtype=dtype)\n",
    "\n",
    "        # loop over all facial landmarks and convert them\n",
    "        # to a 2-tuple of (x, y)-coordinates\n",
    "        for i in range(0, shape.num_parts):\n",
    "            coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\n",
    "        # return the list of (x, y)-coordinates\n",
    "        return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "481b10fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'landmarks_predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dp/_f2qyxmd3xj8tfkjlskp8cg40000gn/T/ipykernel_7261/2443122573.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mface_normalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFaceNormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlandmarks_predictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesiredFaceWidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesiredFaceHeight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheck_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"klava_koka_ii.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgray_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdetected_faces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'landmarks_predictor' is not defined"
     ]
    }
   ],
   "source": [
    "face_normalizer = FaceNormalizer(landmarks_predictor, desiredFaceWidth=150, desiredFaceHeight=150)\n",
    "\n",
    "check_img = load_image(\"klava_koka_ii.jpg\")\n",
    "gray_image = cv2.cvtColor(check_img, cv2.COLOR_BGR2GRAY)\n",
    "detected_faces = detector(check_img, 1)\n",
    "\n",
    "normalizedFace = face_normalizer.align(check_img, gray_image, detected_faces[0])\n",
    "\n",
    "# plt.imshow(normalizedFace)\n",
    "\n",
    "# face_chip = dlib.get_face_chip(check_img, landmarks_predictor(check_img, detected_faces[0]))\n",
    "# plt.imshow(face_chip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d699ff",
   "metadata": {},
   "source": [
    "# Обработчик лица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fe71e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс, который выполняет определение области лица и извлечение из нее вектора признаков\n",
    "class FaceHandler:\n",
    "    \n",
    "    # определение моделей\n",
    "    face_encoder = dlib.face_recognition_model_v1(\"dlib_face_recognition_resnet_model_v1.dat\")\n",
    "    detector = dlib.get_frontal_face_detector()  # определение области лица с помощью HOG\n",
    "    landmarks_predictor = dlib.shape_predictor('shape_predictor_5_face_landmarks.dat')\n",
    "    \n",
    "    # определение экземпляра нормализатора лица\n",
    "    face_normalizer = FaceNormalizer(landmarks_predictor, desiredFaceWidth=150, desiredFaceHeight=150)\n",
    "    \n",
    "    # Функция для определения лица и возвращение вектора 128d\n",
    "    def detect_face_and_encode(self, path_to_img, img_name, image_identify=False):\n",
    "\n",
    "        if image_identify == False:\n",
    "            img_to_recognize = Utilities.load_image(path_to_img + \"/\" + img_name)\n",
    "        else:\n",
    "            img_to_recognize = Utilities.load_image(path_to_img)\n",
    "\n",
    "        detected_faces = self.detector(img_to_recognize, 1) # определение области лица HOG\n",
    "\n",
    "        if len(detected_faces) == 0:\n",
    "            print(\"Error: There is no faces in image!\")\n",
    "            return []\n",
    "\n",
    "        # получение нормализованного лица\n",
    "        gray_image = cv2.cvtColor(img_to_recognize, cv2.COLOR_BGR2GRAY)\n",
    "        normalizedFace = self.face_normalizer.align(img_to_recognize, gray_image, detected_faces[0])\n",
    "        # получение 128d вектора embedding\n",
    "        face_vector = np.array(self.face_encoder.compute_face_descriptor(normalizedFace, num_jitters=1))\n",
    "        return face_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b5113",
   "metadata": {},
   "source": [
    "# Создание базы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a712c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс описывающий базу данных\n",
    "class DataBase:\n",
    "    \n",
    "    known_face_encodings = [] # кодировки лиц из 128d векторов\n",
    "    known_face_names = [] # соответствующие имена векторам\n",
    "    data_labels = [] # соответствующие метки\n",
    "    \n",
    "    def create_db(self, face_handler):\n",
    "\n",
    "        # папка с эталонными фото\n",
    "        root_dir = \"images_db\"\n",
    "        \n",
    "        # удаление скрытого файла\n",
    "        if os.path.exists(root_dir + \"/.DS_Store\"):\n",
    "            os.remove(root_dir + \"/.DS_Store\")\n",
    "            \n",
    "        count_persons = len(os.listdir(root_dir)) # кол-во человек в БД\n",
    "\n",
    "        id_label = 0\n",
    "        for person_dir in os.listdir(root_dir):\n",
    "            print(\"Process person: \" + person_dir + \" - \" + str(id_label + 1) + \"/\" + str(count_persons))\n",
    "\n",
    "            path_to_person = root_dir + \"/\" + person_dir\n",
    "\n",
    "            # удаление скрытого файла\n",
    "            if os.path.exists(path_to_person + \"/.DS_Store\"):\n",
    "                os.remove(path_to_person + \"/.DS_Store\")\n",
    "\n",
    "            imgs_in_person_dir = os.listdir(path_to_person)\n",
    "\n",
    "            # если в папке человека 1 фото, то нужна аугментация\n",
    "            if len(imgs_in_person_dir) == 1:\n",
    "                print(\"Process of augmentation...\")\n",
    "                Augmentator.augmentate_image(path_to_person + \"/\" + imgs_in_person_dir[0])\n",
    "\n",
    "            # обновить список фотографий после аугментации\n",
    "            imgs_in_person_dir = os.listdir(path_to_person)\n",
    "\n",
    "            # проход по всем фото в папке одного человека\n",
    "            for image in imgs_in_person_dir:\n",
    "                print(image)\n",
    "\n",
    "                # определение области лица и получение закодированного лица\n",
    "                encoded_face = face_handler.detect_face_and_encode(path_to_person, image)\n",
    "                # добавление закодированного лица в БД\n",
    "                if len(encoded_face) == 128:\n",
    "                    self.add_to_db(encoded_face, id_label, person_dir)\n",
    "\n",
    "            id_label += 1 # изменения номера отметки для следующего человека\n",
    "        \n",
    "        print(self.known_face_names)\n",
    "    \n",
    "    #функция для добавления вектора лица в БД\n",
    "    def add_to_db(self, vector_128d, id_num, person_name):\n",
    "\n",
    "        self.known_face_encodings.append(vector_128d)\n",
    "        self.known_face_names.append(person_name)\n",
    "        self.data_labels.append(id_num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3399c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DB from file...\n"
     ]
    }
   ],
   "source": [
    "data_base = DataBase()\n",
    "\n",
    "face_handler = FaceHandler()\n",
    "\n",
    "# если нужна сохраненная БД\n",
    "need_new_DB = False\n",
    "\n",
    "if need_new_DB == False:\n",
    "    # используется сохраненная база\n",
    "    data_from_existing_DB = Serializer_DB.read_data_from_file()\n",
    "    data_base.known_face_encodings = data_from_existing_DB[\"encodings\"]\n",
    "    data_base.known_face_names = data_from_existing_DB[\"names\"]\n",
    "    data_base.data_labels = data_from_existing_DB[\"labels\"]\n",
    "else:\n",
    "    # Вызов функции для создания БД: флаг False - если аугментация не нужна\n",
    "    data_base.create_db(face_handler)\n",
    "    # сериализация данных в файл\n",
    "    Serializer_DB.save_data_to_file(data_base.known_face_encodings, data_base.known_face_names, data_base.data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c427c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8b8fcc9",
   "metadata": {},
   "source": [
    "# Аугментация фотографии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7091e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс, отвечающий за расширение обучающего набора эталонного изображения\n",
    "class Augmentator:\n",
    "    \n",
    "    @staticmethod\n",
    "    def augmentate_image(path_to_image):\n",
    "\n",
    "        # получение пути к фото и названия фото\n",
    "        head_tail = os.path.split(path_to_image)\n",
    "        path_dir = head_tail[0]\n",
    "        img_name = head_tail[1]\n",
    "\n",
    "        # загрузка изображения\n",
    "        img = Utilities.load_image(path_to_image)\n",
    "\n",
    "        flag_flip = 1.0\n",
    "        brightness_dark = -10\n",
    "        brightness_light = 10\n",
    "\n",
    "        for i in range(6):\n",
    "            aug_pipeline = iaa.Sequential([\n",
    "\n",
    "            iaa.Affine(scale=(0.8, 1.1)),\n",
    "            iaa.Crop(percent=(0, 0.15)),\n",
    "            iaa.Fliplr(flag_flip),\n",
    "            iaa.AddToBrightness((brightness_dark, brightness_light))\n",
    "            ],\n",
    "            random_order=True)\n",
    "\n",
    "            augmented_photo = np.array(aug_pipeline.augment_image(img))\n",
    "\n",
    "            # сохранения аугментированного изображения\n",
    "            new_img_name = path_dir + \"/\" + str(i + 1) + \".jpg\"\n",
    "            cv2.imwrite(new_img_name, cv2.cvtColor(augmented_photo, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            # изменение параметров\n",
    "            flag_flip = 0.0 if flag_flip == 1.0 else 1.0\n",
    "            brightness_dark -= 20\n",
    "        #     brightness_light += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a74fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentate_image(\"images_db/Aaron_Piersol/Aaron_Piersol.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7b07eb",
   "metadata": {},
   "source": [
    "# KNN классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96027b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN алгоримт\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Classifier:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X_train = []\n",
    "        self.X_test = []\n",
    "        self.y_train = []\n",
    "        self.y_test = []\n",
    "        \n",
    "        self.classifier = None\n",
    "    \n",
    "    # метод для обучения классификатора\n",
    "    # data - данные изображения людей базы данных\n",
    "    def train_classifier_KNN(self, data):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(data.known_face_encodings, \n",
    "                                                                                data.data_labels, \n",
    "                                                                                test_size=0.3)\n",
    "        \n",
    "        self.classifier = KNeighborsClassifier(n_neighbors = 3, metric=self.my_dist)\n",
    "        self.classifier.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        print(\"Re-FIT KNN!\")\n",
    "\n",
    "    def my_dist(self, x, y):\n",
    "    \n",
    "        diff = np.linalg.norm(x - y)\n",
    "        if diff > 0.6:\n",
    "    #         print(\"ZERO\")\n",
    "            return 1\n",
    "        else:\n",
    "    #         print(\"GOOD\")\n",
    "            return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "452ed18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-FIT KNN!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 5,  6, 10,  7,  2,  2,  0,  4,  2,  8,  0,  3,  0,  2,  9,  9,  8,\n",
       "        9,  9,  4,  7,  3,  4,  7])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_classifier = Classifier()\n",
    "\n",
    "my_classifier.train_classifier_KNN(data_base)\n",
    "\n",
    "yhat_class = my_classifier.classifier.predict(my_classifier.X_test)\n",
    "yhat_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b1d5531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 10, 7, 2, 2, 0, 4, 2, 8, 0, 3, 0, 2, 9, 9, 8, 9, 9, 4, 7, 3, 4, 7]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_classifier.y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ca4ef",
   "metadata": {},
   "source": [
    "# Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de380e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс, содержащий вспомогательные функции\n",
    "class Utilities:\n",
    "    \n",
    "    # преобразование массива known_name, где повторяются имена людей\n",
    "    @staticmethod\n",
    "    def get_unique_values(values):\n",
    "        uniques = []\n",
    "        for v in values:\n",
    "            if v not in uniques:\n",
    "                uniques.append(v)\n",
    "        return uniques\n",
    "    \n",
    "    # функция для загрузки фотографии\n",
    "    @staticmethod\n",
    "    def load_image(path_to_image):\n",
    "        img = PIL.Image.open(path_to_image)\n",
    "        \n",
    "        return np.array(img)\n",
    "    \n",
    "    @staticmethod    \n",
    "    def rect_to_box(rect):\n",
    "        # преобразование квадрата, предсказанного dlib, \n",
    "        # в формат (x, y, w, h), который обычно используется в OpenCV\n",
    "        x = rect.left()\n",
    "        y = rect.top()\n",
    "        w = rect.right()\n",
    "        h = rect.bottom()\n",
    "\n",
    "        # return a tuple of (x, y, w, h)\n",
    "        return (x, y, w, h)\n",
    "\n",
    "        return np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8ba18",
   "metadata": {},
   "source": [
    "# Окно приложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "119dbd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowApp:\n",
    "    \n",
    "    root = Tk()\n",
    "    # путь к изображению, выбранного для идентификации \n",
    "    path_img_to_identify = \"\"\n",
    "    \n",
    "    # путь к изображению для нового человека (при добавлении человека)\n",
    "    path_to_new_person = \"\"\n",
    "    \n",
    "    def __init__(self, handler_for_face, data_base, classificator):\n",
    "        self.handler_for_face = handler_for_face\n",
    "        self.data_base = data_base\n",
    "        self.my_classif = classificator\n",
    "    \n",
    "    def create_ui(self):\n",
    "        self.root.title(\"Ідентифікація людини\")\n",
    "        self.root.geometry(\"1000x600\")\n",
    "        self.root.resizable(width=False, height=False)\n",
    "        self.root.configure(background='#c2d6d6')\n",
    "\n",
    "        # =========== LEFT SIDE ==============\n",
    "        self.frame_left = Frame(self.root, bg='gray')\n",
    "        self.frame_left.place(relx=0.01, rely=0.05, relwidth=0.47, relheight=0.8)\n",
    "\n",
    "        self.button_choose = Button(self.frame_left, text=\"Обрати зображення\", command=self.show_image, background=\"#527a7a\", font=\"Arial 14\")\n",
    "        self.button_choose.place(relx=0.1, rely=0.85, relwidth=0.3, relheight=0.07)\n",
    "\n",
    "        self.photo_left = Label(self.frame_left)\n",
    "        self.photo_left.place(relx=0.02, rely=0.1, relwidth=0.96, relheight=0.7)\n",
    "\n",
    "        self.text_id_photo = Label(self.frame_left, text=\"Зображення для ідентифікації\", font=\"Arial 16\", bg='gray', fg='white')\n",
    "        self.text_id_photo.pack(side=tk.TOP)\n",
    "\n",
    "        # =========== RIGHT SIDE ==============\n",
    "        self.frame_right = Frame(self.root, bg='gray')\n",
    "        self.frame_right.place(relx=0.51, rely=0.05, relwidth=0.48, relheight=0.8)\n",
    "\n",
    "        self.photo_right = Label(self.frame_right)\n",
    "        self.photo_right.place(relx=0.02, rely=0.1, relwidth=0.96, relheight=0.7)\n",
    "\n",
    "        self.text_right_photo = Label(self.frame_right, text=\"Знайдена людина у БД\", font=\"Arial 16\", bg='gray', fg='white')\n",
    "        self.text_right_photo.pack(side=tk.TOP)\n",
    "\n",
    "        self.text_name_person = Label(self.frame_right, text=\"Им'я: \", font=\"Arial 16\", bg='gray', fg='white')\n",
    "        self.text_name_person.place(relx=0.05, rely=0.85)\n",
    "\n",
    "        self.button_add_person = Button(self.frame_right, text=\"Додати людину до БД\", command=self.add_person_to_db, background=\"#527a7a\", font=\"Arial 14\")\n",
    "        self.button_add_person.place(relx=0.58, rely=0.92, relwidth=0.4, relheight=0.07)\n",
    "\n",
    "        # =========== BOTTOM SIDE ==============\n",
    "        self.button_recognize = Button(self.root, text=\"Ідентифікувати\", command=self.recognize_person, background=\"#527a7a\", font=\"Arial 16\")\n",
    "        self.button_recognize.place(relx=0.35, rely=0.9, relwidth=0.3, relheight=0.08)\n",
    "\n",
    "    # Метод-обработчик для выбора фото при нажатии кнопки \"Обрати фото\"\n",
    "    def show_image(self):\n",
    "        \n",
    "        fln = filedialog.askopenfilename(initialdir=os.getcwd(), title=\"Вибір фото\",\n",
    "                                        filetypes=((\"JPG File\", \"*.jpg\"),\n",
    "                                                   (\"JPEG File\", \"*.jpeg\"),\n",
    "                                                   (\"PNG File\", \"*.png\"),\n",
    "                                                   (\"All files\", \"*.*\")))\n",
    "\n",
    "        img = Image.open(fln)\n",
    "        img.thumbnail((400,400))\n",
    "        img = ImageTk.PhotoImage(img)\n",
    "        self.photo_left.configure(image=img)\n",
    "        self.photo_left.image = img\n",
    "        self.path_img_to_identify = fln\n",
    "    \n",
    "    # Метод-обработчик при нажатии кнопки \"Ідентифікувати\"\n",
    "    def recognize_person(self):\n",
    "    \n",
    "        flag_found = False\n",
    "\n",
    "        img_to_recognize = Utilities.load_image(self.path_img_to_identify)\n",
    "        detected_faces = self.handler_for_face.detector(img_to_recognize, 1) # определение области лица HOG\n",
    "\n",
    "        if len(detected_faces) == 0:\n",
    "            print(\"Error: There is no faces!\")\n",
    "            return\n",
    "\n",
    "        # извлечение 128 вектора из фото для идентификации\n",
    "        encoded_face = face_handler.detect_face_and_encode(self.path_img_to_identify, \"\", image_identify=True)\n",
    "\n",
    "        # KNN predict\n",
    "        check = self.my_classif.classifier.predict_proba([encoded_face])\n",
    "        print(check)\n",
    "\n",
    "        box_face = Utilities.rect_to_box(detected_faces[0])\n",
    "\n",
    "        name_of_person = \"Особи немає у базі даних\"\n",
    "\n",
    "        # =========== Использование KNN ===========\n",
    "        value_predict = np.amax(check)\n",
    "        value_index = check.argmax()\n",
    "        if value_predict > 0.6:\n",
    "            flag_found = True\n",
    "            name_of_person = Utilities.get_unique_values(self.data_base.known_face_names)[value_index]\n",
    "\n",
    "        # =========================================\n",
    "\n",
    "        cv2.rectangle(img_to_recognize, (box_face[0], box_face[1]), (box_face[2], box_face[3]), (0, 255, 0), 2)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        #cv2.putText(img_to_recognize, name_of_person, (box_face[0], box_face[3]), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        # ============ ОТОБРАЖЕНИЕ В ОКНЕ ПРИЛОЖЕНИЯ ===============\n",
    "        # отрисовка слева фото с выделенным лицом\n",
    "        img_recognize = Image.fromarray(img_to_recognize)\n",
    "        img_recognize.thumbnail((400,400))\n",
    "        img_recognize = ImageTk.PhotoImage(img_recognize)\n",
    "        self.photo_left.configure(image=img_recognize)\n",
    "        self.photo_left.image = img_recognize\n",
    "\n",
    "        # Если человек найден - отобразить его фото из БД\n",
    "        if flag_found == True:\n",
    "            img_in_db = Image.open(\"images_db/\" + name_of_person + \"/\" + name_of_person + \".jpg\")\n",
    "            img_in_db.thumbnail((400,400))\n",
    "            img_in_db = ImageTk.PhotoImage(img_in_db)\n",
    "            self.photo_right.configure(image=img_in_db)\n",
    "            self.photo_right.image = img_in_db\n",
    "        else: # Иначе отобразить фото Инкогнито\n",
    "            unknown_img = Image.open(\"Unknown_person.png\")\n",
    "            unknown_img.thumbnail((400,400))\n",
    "            unknown_img = ImageTk.PhotoImage(unknown_img)\n",
    "            self.photo_right.configure(image=unknown_img)\n",
    "            self.photo_right.image = unknown_img\n",
    "\n",
    "        self.text_name_person.config(text=\"Имя: \" + name_of_person)\n",
    "        \n",
    "    # ============== ОКНО ДОБАВЛЕНИЯ ЧЕЛОВЕКА =============\n",
    "    \n",
    "    # Метод-обработчик для кнпоки \"Додати людину до БД\"    \n",
    "    def add_person_to_db(self):\n",
    "\n",
    "        new_window = tk.Toplevel(self.root)\n",
    "\n",
    "        new_window.title(\"Додавання людини до БД\")\n",
    "        new_window.geometry(\"480x240\")\n",
    "        new_window.resizable(width=False, height=False)\n",
    "        new_window.configure(background='#a3c2c2')\n",
    "\n",
    "        self.name_choosed_img = Label(new_window, text=\"Зображення не обране!\", font=\"Arial 20\", bg='#a3c2c2', fg='#ffffff', borderwidth=2)\n",
    "        self.name_choosed_img.place(relx=0.05, rely=0.2)\n",
    "\n",
    "        button_choose_photo = tk.Button(new_window, text = \"Обрати фото\", command=self.choose_person_img)\n",
    "        button_choose_photo.place(relx=0.75, rely=0.2, relwidth=0.2, relheight=0.15)\n",
    "\n",
    "        text_input_name = Label(new_window, text=\"Введіть им'я: \", font=\"Arial 20\", bg='#a3c2c2', fg='#ffffff', borderwidth=2)\n",
    "        text_input_name.place(relx=0.10, rely=0.5)\n",
    "\n",
    "        entry_field = Entry(new_window)\n",
    "        entry_field.place(relx=0.40, rely=0.5, relwidth=0.5)\n",
    "\n",
    "        def add_func():\n",
    "            new_dir_name = \"images_db/\" + entry_field.get()\n",
    "            # создание новой папки для человека\n",
    "            os.mkdir(new_dir_name)\n",
    "            # копирование в папку выбранной фотографии\n",
    "            shutil.copyfile(self.path_to_new_person, new_dir_name + \"/\" + entry_field.get() + \".jpg\")\n",
    "\n",
    "            new_path_to_image = new_dir_name + \"/\" + entry_field.get() + \".jpg\"\n",
    "            # выполнение аугментации\n",
    "            Augmentator.augmentate_image(new_path_to_image)\n",
    "\n",
    "            # получить 128-признаки из аугментированных фото\n",
    "            self.process_person_img(new_dir_name, entry_field.get())\n",
    "\n",
    "            new_window.destroy()\n",
    "\n",
    "        button_add = Button(new_window, text = \"Додати\", command=add_func)\n",
    "        button_add.place(relx=0.4, rely=0.8, relwidth=0.2, relheight=0.15)\n",
    "\n",
    "    # открытие проводника для выбора фото\n",
    "    def choose_person_img(self):\n",
    "\n",
    "        fln = filedialog.askopenfilename(initialdir=os.getcwd(), title=\"Вибір фото\",\n",
    "                                        filetypes=((\"JPG File\", \"*.jpg\"),\n",
    "                                                   (\"JPEG File\", \"*.jpeg\"),\n",
    "                                                   (\"PNG File\", \"*.png\"),\n",
    "                                                   (\"All files\", \"*.*\")))\n",
    "        self.path_to_new_person = fln\n",
    "\n",
    "\n",
    "        img_name = os.path.split(self.path_to_new_person)[1]\n",
    "        self.name_choosed_img.config(text=\"Зображення: \" + img_name)\n",
    "\n",
    "    \n",
    "    def process_person_img(self, path_to_dir, name_person):\n",
    "        # получение последнего номера класса\n",
    "        id_new_person = self.data_base.data_labels[-1] + 1\n",
    "\n",
    "        # проход по всем фотографиям нового человека\n",
    "        for img_in_person_dir in os.listdir(path_to_dir):\n",
    "\n",
    "            # получение закодированного лица\n",
    "            encoded_face = self.handler_for_face.detect_face_and_encode(path_to_dir, img_in_person_dir)\n",
    "            # добавление закодированного лица в БД\n",
    "            if len(encoded_face) == 128:\n",
    "                self.data_base.add_to_db(encoded_face, id_new_person, name_person)\n",
    "\n",
    "        # сохранение обновленной БД в файл\n",
    "        Serializer_DB.save_data_to_file(self.data_base.known_face_encodings, self.data_base.known_face_names, self.data_base.data_labels)\n",
    "        # переобучение классификатора\n",
    "        self.my_classif.train_classifier_KNN(self.data_base)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "804e2bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.         0.         0.         0.33333333 0.\n",
      "  0.33333333 0.         0.         0.         0.        ]]\n",
      "Writing DB to file...\n",
      "Re-FIT KNN!\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.66666667\n",
      "  0.33333333]]\n",
      "[[0.33333333 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.33333333 0.33333333 0.         0.\n",
      "  0.        ]]\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.66666667\n",
      "  0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "# ==== Точка запуска программы ====\n",
    "main_window = WindowApp(face_handler, data_base, my_classifier)\n",
    "main_window.create_ui()\n",
    "\n",
    "main_window.root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ed740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b47e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
