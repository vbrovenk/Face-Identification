{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "import tkinter as tk\n",
    "import PIL.Image\n",
    "from PIL import Image, ImageTk\n",
    "from PIL import ImageDraw # для отрисовки 68 landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import dlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормализация фотографии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "FACIAL_LANDMARKS_5_IDXS = OrderedDict([\n",
    "    (\"right_eye\", (2, 3)),\n",
    "    (\"left_eye\", (0, 1)),\n",
    "    (\"nose\", (4))\n",
    "])\n",
    "\n",
    "def rect_to_box(rect):\n",
    "    # take a bounding predicted by dlib and convert it\n",
    "    # to the format (x, y, w, h) as we would normally do\n",
    "    # with OpenCV\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right()\n",
    "    h = rect.bottom()\n",
    "\n",
    "    # return a tuple of (x, y, w, h)\n",
    "    return (x, y, w, h)\n",
    "\n",
    "# dlib object -> np.array\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    # initialize the list of (x, y)-coordinates\n",
    "    coords = np.zeros((shape.num_parts, 2), dtype=dtype)\n",
    "\n",
    "    # loop over all facial landmarks and convert them\n",
    "    # to a 2-tuple of (x, y)-coordinates\n",
    "    for i in range(0, shape.num_parts):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\n",
    "    # return the list of (x, y)-coordinates\n",
    "    return coords\n",
    "\n",
    "class FaceNormalizer:\n",
    "    \n",
    "    def __init__(self, predictor, desiredLeftEye=(0.33, 0.33),\n",
    "        desiredFaceWidth=256, desiredFaceHeight=None):\n",
    "        # сохранение определителя ключевых точек лица, желаемая позиция левого глаза\n",
    "        # и желаемая ширина и высота лица на выходящем изображении\n",
    "        self.predictor_landmarks = predictor\n",
    "        self.desiredLeftEye = desiredLeftEye\n",
    "        self.desiredFaceWidth = desiredFaceWidth\n",
    "        self.desiredFaceHeight = desiredFaceHeight\n",
    "        # if the desired face height is None, set it to be the\n",
    "        # desired face width (normal behavior)\n",
    "        if self.desiredFaceHeight is None:\n",
    "            self.desiredFaceHeight = self.desiredFaceWidth\n",
    "            \n",
    "    # функция для нормализации лица\n",
    "    # image - изображение в RGB \n",
    "    # gray - серое изображение\n",
    "    # rect - область лица, выделенная HOG\n",
    "    def align(self, image, gray, rect):\n",
    "        # получение 5 ориентиров-landmarks\n",
    "        shape = self.predictor_landmarks(image, rect)\n",
    "        # преобразование dlib object в np.array\n",
    "        shape = shape_to_np(shape)\n",
    "        \n",
    "        # извлечение левого и правого глаз (x, y)-coordinates\n",
    "        (lStart, lEnd) = FACIAL_LANDMARKS_5_IDXS[\"left_eye\"]\n",
    "        (rStart, rEnd) = FACIAL_LANDMARKS_5_IDXS[\"right_eye\"]\n",
    "        # извлечение точек левого глаза и правого (x, y)-coordinates\n",
    "        leftEyePts = shape[lStart:lEnd + 1]\n",
    "        rightEyePts = shape[rStart:rEnd + 1]\n",
    "        \n",
    "        # расчет центра для каждого глаза\n",
    "        leftEyeCenter = leftEyePts.mean(axis=0).astype(\"int\")\n",
    "        rightEyeCenter = rightEyePts.mean(axis=0).astype(\"int\")\n",
    "        # расчет угла между центроидами глаз\n",
    "        dY = rightEyeCenter[1] - leftEyeCenter[1]\n",
    "        dX = rightEyeCenter[0] - leftEyeCenter[0]\n",
    "        angle = np.degrees(np.arctan2(dY, dX)) - 180\n",
    "        #print(angle)\n",
    "        \n",
    "        # вычисление х-коорд правого глаза основанной на x-коорд левого глаза\n",
    "        desiredRightEyeX = 1.0 - self.desiredLeftEye[0]\n",
    "        # определение масштаба результирующего изображения, взяв\n",
    "        # отношение расстояния между глазами в текущем изображении\n",
    "        # к отношению расстояния глаз в желаемом изображении\n",
    "        dist = np.sqrt((dX ** 2) + (dY ** 2)) # Евклидово расстояние\n",
    "        desiredDist = (desiredRightEyeX - self.desiredLeftEye[0]) # \n",
    "        desiredDist *= self.desiredFaceWidth\n",
    "        scale = desiredDist / dist\n",
    "        \n",
    "        # вычисление центра между глазами (x, y)-coordinates\n",
    "        # для вращения фотографии вокруг этого центра\n",
    "        eyesCenter = ((leftEyeCenter[0] + rightEyeCenter[0]) / 2,\n",
    "        (leftEyeCenter[1] + rightEyeCenter[1]) / 2)\n",
    "        #print(\"eyesCenter = \" + str(eyesCenter))\n",
    "        \n",
    "        # получение матрицы для поворота и масштабирования лица\n",
    "        M = cv2.getRotationMatrix2D(center=eyesCenter, angle=angle, scale=scale)\n",
    "        \n",
    "        # обновление компонентов матрицы на смещение\n",
    "        tX = self.desiredFaceWidth * 0.5\n",
    "        tY = self.desiredFaceHeight * self.desiredLeftEye[1]\n",
    "        M[0, 2] += (tX - eyesCenter[0])\n",
    "        M[1, 2] += (tY - eyesCenter[1])\n",
    "        \n",
    "        # применение аффинного преобразования\n",
    "        (w, h) = (self.desiredFaceWidth, self.desiredFaceHeight)\n",
    "        output = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # возвращение нормализованного лица\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_normalizer = FaceNormalizer(landmarks_predictor, desiredFaceWidth=150, desiredFaceHeight=150)\n",
    "\n",
    "check_img = load_image(\"klava_koka_ii.jpg\")\n",
    "gray_image = cv2.cvtColor(check_img, cv2.COLOR_BGR2GRAY)\n",
    "detected_faces = detector(check_img, 1)\n",
    "\n",
    "normalizedFace = face_normalizer.align(check_img, gray_image, detected_faces[0])\n",
    "\n",
    "# plt.imshow(normalizedFace)\n",
    "\n",
    "# face_chip = dlib.get_face_chip(check_img, landmarks_predictor(check_img, detected_faces[0]))\n",
    "# plt.imshow(face_chip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание БД кодировок фотографий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для загрузки фотографии\n",
    "def load_image(path_to_image):\n",
    "    img = PIL.Image.open(path_to_image)\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "# определение моделей\n",
    "face_encoder = dlib.face_recognition_model_v1(\"dlib_face_recognition_resnet_model_v1.dat\")\n",
    "detector = dlib.get_frontal_face_detector()  # определение области лица с помощью HOG\n",
    "landmarks_predictor = dlib.shape_predictor('shape_predictor_5_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#функция для добавления вектора лица в БД\n",
    "def add_to_db(vector_128d, id_num, person_name):\n",
    "    \n",
    "    known_face_encodings.append(vector_128d)\n",
    "    known_face_names.append(person_name)\n",
    "    data_labels.append(id_num)\n",
    "\n",
    "# Функция для определения лица и возвращение вектора 128d\n",
    "def detect_face_and_encode(path_to_img, img_name, image_identify=False):\n",
    "    \n",
    "    # ======== lib Face Recognition ============\n",
    "#     img_to_recognize = face_recognition.load_image_file(path_to_img + \"/\" + img_name)\n",
    "#     face_locations = face_recognition.face_locations(img_to_recognize, model=\"hog\")\n",
    "#     face_encodings = face_recognition.face_encodings(img_to_recognize, face_locations)\n",
    "    \n",
    "    if image_identify == False:\n",
    "        img_to_recognize = load_image(path_to_img + \"/\" + img_name)\n",
    "    else:\n",
    "        img_to_recognize = load_image(path_to_img)\n",
    "        \n",
    "    detected_faces = detector(img_to_recognize, 1) # определение области лица HOG\n",
    "    \n",
    "    if len(detected_faces) != 1:\n",
    "        print(\"На фото нет лиц или больше чем 1 лицо!\")\n",
    "        return []\n",
    "    \n",
    "    # определение экземпляра нормализатора лица\n",
    "    face_normalizer = FaceNormalizer(landmarks_predictor, desiredFaceWidth=150, desiredFaceHeight=150)\n",
    "    \n",
    "    gray_image = cv2.cvtColor(img_to_recognize, cv2.COLOR_BGR2GRAY)\n",
    "    normalizedFace = face_normalizer.align(img_to_recognize, gray_image, detected_faces[0])\n",
    "    \n",
    "    face_vector = np.array(face_encoder.compute_face_descriptor(normalizedFace, num_jitters=1))\n",
    "    return face_vector\n",
    "    \n",
    "\n",
    "def create_db(need_augmentate=False):\n",
    "\n",
    "    root_dir = \"images_db\"\n",
    "    count_persons = len(os.listdir(root_dir)) # кол-во человек в БД\n",
    "    id_label = 0\n",
    "    for person_dir in os.listdir(root_dir):\n",
    "        print(\"Process person: \" + person_dir + \" - \" + str(id_label + 1) + \"/\" + str(count_persons))\n",
    "\n",
    "        path_to_person = root_dir + \"/\" + person_dir\n",
    "        imgs_in_person_dir = os.listdir(path_to_person)\n",
    "        for image in imgs_in_person_dir:\n",
    "            print(image)\n",
    "            if need_augmentate == True:\n",
    "                print(image)\n",
    "                augment_photo(path_to_person, image)\n",
    "                # проход по всем фото и добавление в БД, так как появились новые фото    \n",
    "                for img_in_person_dir in os.listdir(path_to_person):\n",
    "                    print(img_in_person_dir)\n",
    "            else:\n",
    "                # получение закодированного лица\n",
    "                encoded_face = detect_face_and_encode(path_to_person, image)\n",
    "                # добавление закодированного лица в БД\n",
    "                if len(encoded_face) == 128:\n",
    "                    add_to_db(encoded_face, id_label, person_dir)\n",
    "\n",
    "        id_label += 1 # изменения номера отметки для следующего человека"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process person: Justin_Bieber - 1/4\n",
      "10.jpg\n",
      "11.jpg\n",
      "6.jpg\n",
      "7.jpg\n",
      "8.jpg\n",
      "9.jpg\n",
      "Justin_Bieber.jpg\n",
      "Process person: Khabib_Nurmagomedov - 2/4\n",
      "10.jpg\n",
      "11.jpg\n",
      "6.jpg\n",
      "7.jpg\n",
      "8.jpg\n",
      "9.jpg\n",
      "Khabib_Nurmagomedov.jpg\n",
      "Process person: Mikhail_Litvin - 3/4\n",
      "10.jpg\n",
      "11.jpg\n",
      "6.jpg\n",
      "7.jpg\n",
      "8.jpg\n",
      "9.jpg\n",
      "Mikhail_Litvin.jpg\n",
      "Process person: Vadim_Brovenko - 4/4\n",
      "10.jpg\n",
      "11.jpg\n",
      "6.jpg\n",
      "7.jpg\n",
      "8.jpg\n",
      "9.jpg\n",
      "Vadim_Brovenko.jpg\n"
     ]
    }
   ],
   "source": [
    "known_face_encodings = [] # кодировки лиц из 128d векторов\n",
    "known_face_names = [] # соответствующие имена векторам\n",
    "data_labels = [] # соответствующие метки\n",
    "\n",
    "# Вызов функции для создания БД: флаг False - если аугментация не нужна\n",
    "create_db(need_augmentate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция для выбора фото"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image():\n",
    "    global path_img_to_identify\n",
    "    \n",
    "    fln = filedialog.askopenfilename(initialdir=os.getcwd(), title=\"Выбор фото\",\n",
    "                                    filetypes=((\"JPG File\", \"*.jpg\"), \n",
    "                                               (\"PNG File\", \"*.png\"),\n",
    "                                               (\"All files\", \"*.*\")))\n",
    "    \n",
    "    img = Image.open(fln)\n",
    "    img.thumbnail((400,400))\n",
    "    img = ImageTk.PhotoImage(img)\n",
    "    photo_left.configure(image=img)\n",
    "    photo_left.image = img\n",
    "    path_img_to_identify = fln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN алгоримт\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(known_face_encodings, data_labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric=<function my_dist at 0x0000000031551CA0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_dist(x, y):\n",
    "    \n",
    "    diff = np.linalg.norm(x - y)\n",
    "    if diff > 0.6:\n",
    "#         print(\"ZERO\")\n",
    "        return 1\n",
    "    else:\n",
    "#         print(\"GOOD\")\n",
    "        return diff\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric=my_dist)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 1, 0, 3, 3, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_class = classifier.predict(X_test)\n",
    "yhat_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 2, 1, 0, 3, 3, 0]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_numbers(values):\n",
    "    unique = []\n",
    "    for number in values:\n",
    "        if number not in unique:\n",
    "            unique.append(number)\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция для кнопки Распознать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_person():\n",
    "    \n",
    "    flag_found = False\n",
    "    \n",
    "#     img_to_recognize = face_recognition.load_image_file(path_img_to_recognize)\n",
    "#     face_locations = face_recognition.face_locations(img_to_recognize, model=\"hog\")\n",
    "#     face_encodings = face_recognition.face_encodings(img_to_recognize, face_locations)\n",
    "    \n",
    "    img_to_recognize = load_image(path_img_to_identify)\n",
    "    detected_faces = detector(img_to_recognize, 1) # определение области лица HOG\n",
    "    \n",
    "    if len(detected_faces) != 1:\n",
    "        print(\"На фото нет лиц или больше чем 1 лицо!\")\n",
    "        return\n",
    "\n",
    "    encoded_face = detect_face_and_encode(path_img_to_identify, \"\", image_identify=True)\n",
    "    \n",
    "    # KNN predict\n",
    "    check = classifier.predict_proba([encoded_face])\n",
    "    print(check)\n",
    "    box_face = rect_to_box(detected_faces[0])\n",
    "        \n",
    "    name_of_person = \"Unknown face\"\n",
    "\n",
    "    # =========== Использование KNN ===========\n",
    "    value_predict = np.amax(check)\n",
    "    value_index = check.argmax()\n",
    "    if value_predict > 0.6:\n",
    "        flag_found = True\n",
    "        name_of_person = get_unique_numbers(known_face_names)[value_index]\n",
    "        \n",
    "    # =========================================\n",
    "\n",
    "    cv2.rectangle(img_to_recognize, (box_face[0], box_face[1]), (box_face[2], box_face[3]), (0, 255, 0), 2)\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    #cv2.putText(img_to_recognize, name_of_person, (box_face[0], box_face[3]), font, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    # ============ ОТОБРАЖЕНИЕ В ОКНЕ ПРИЛОЖЕНИЯ ===============\n",
    "    # отрисовка слева фото с выделенным лицом\n",
    "    img_recognize = Image.fromarray(img_to_recognize)\n",
    "    img_recognize.thumbnail((400,400))\n",
    "    img_recognize = ImageTk.PhotoImage(img_recognize)\n",
    "    photo_left.configure(image=img_recognize)\n",
    "    photo_left.image = img_recognize\n",
    "        \n",
    "    # Если человек найден - отобразить его фото из БД\n",
    "    if flag_found == True:\n",
    "        img_in_db = Image.open(\"images_db\\\\\" + name_of_person + \"\\\\\" + name_of_person + \".jpg\")\n",
    "        img_in_db.thumbnail((400,400))\n",
    "        img_in_db = ImageTk.PhotoImage(img_in_db)\n",
    "        photo_right.configure(image=img_in_db)\n",
    "        photo_right.image = img_in_db\n",
    "    else: # Иначе отобразить фото Инкогнито\n",
    "        unknown_img = Image.open(\"Unknown_person.png\")\n",
    "        unknown_img.thumbnail((400,400))\n",
    "        unknown_img = ImageTk.PhotoImage(unknown_img)\n",
    "        photo_right.configure(image=unknown_img)\n",
    "        photo_right.image = unknown_img\n",
    "        \n",
    "    text_name_person.config(text=\"Имя: \" + name_of_person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Окно приложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "root.title(\"Face Recognizer App\")\n",
    "root.geometry(\"1000x600\")\n",
    "root.resizable(width=False, height=False)\n",
    "root.configure(background='#0d261a')\n",
    "\n",
    "# =========== LEFT SIDE ==============\n",
    "frame_left = Frame(root, bg='gray')\n",
    "frame_left.place(relx=0.01, rely=0.05, relwidth=0.47, relheight=0.8)\n",
    "\n",
    "button_choose = Button(frame_left, text=\"Выбрать фото\", command=show_image, background=\"#527a7a\", foreground=\"#ffffff\", font=\"Arial 14\")\n",
    "button_choose.place(relx=0.1, rely=0.85, relwidth=0.3, relheight=0.07)\n",
    "\n",
    "photo_left = Label(frame_left)\n",
    "photo_left.place(relx=0.02, rely=0.1, relwidth=0.96, relheight=0.7)\n",
    "\n",
    "text_id_photo = Label(frame_left, text=\"Фото для идентификации\", font=\"Arial 16\", bg='gray')\n",
    "text_id_photo.pack(side=tk.TOP)\n",
    "\n",
    "# =========== RIGHT SIDE ==============\n",
    "frame_right = Frame(root, bg='gray')\n",
    "frame_right.place(relx=0.51, rely=0.05, relwidth=0.48, relheight=0.8)\n",
    "\n",
    "photo_right = Label(frame_right)\n",
    "photo_right.place(relx=0.02, rely=0.1, relwidth=0.96, relheight=0.7)\n",
    "\n",
    "text_right_photo = Label(frame_right, text=\"Найденный человек в БД\", font=\"Arial 16\", bg='gray')\n",
    "text_right_photo.pack(side=tk.TOP)\n",
    "\n",
    "text_name_person = Label(frame_right, text=\"Имя: \", font=\"Arial 16\", bg='gray')\n",
    "text_name_person.place(relx=0.05, rely=0.87)\n",
    "\n",
    "# ========== TOP RESULTS ===========\n",
    "# text_distance = Label(root, text=\"Расстояние: 0.0\", bg='gray')\n",
    "# text_distance.pack(side=tk.TOP)\n",
    "\n",
    "button_recognize = Button(root, text=\"Распознать\", command=recognize_person, background=\"#527a7a\", foreground=\"#ffffff\", font=\"Arial 16\")\n",
    "button_recognize.place(relx=0.35, rely=0.9, relwidth=0.3, relheight=0.08)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
